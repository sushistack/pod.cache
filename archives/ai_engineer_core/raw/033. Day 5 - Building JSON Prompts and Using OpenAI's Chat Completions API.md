# 033. 📈 LLM 프롬프트 최적화- JSON, 예시, 그리고 응답 포맷 강제

이 아티클에서는 대규모 언어 모델(LLM)로부터 원하는 형식의 응답을 얻기 위한 프롬프트 엔지니어링 기법을 다룹니다. 시스템 및 사용자 프롬프트의 설계 원칙을 이해하고, JSON을 활용한 구조화된 출력 방식과 One-Shot 프롬프팅의 효과를 알아봅니다. 특히 `response_format` 파라미터를 사용하여 LLM의 JSON 응답을 강제하는 방법을 통해 개발자가 더욱 정확하고 안정적인 LLM 애플리케이션을 구축할 수 있도록 돕습니다.

---

## 🚀 서론: LLM 응답을 제어하는 예술, 프롬프트 엔지니어링

최근 대규모 언어 모델(LLM)의 발전은 개발자들에게 무한한 가능성을 열어주었습니다. 하지만 "어떻게 하면 LLM으로부터 내가 *정확히 원하는* 형태의 응답을 얻을 수 있을까?"라는 질문은 여전히 많은 개발자의 고민입니다. 단순히 질문을 던지는 것을 넘어, LLM이 이해하고 따라야 할 명확한 지침을 제공하는 것이 중요합니다. 이 글에서는 LLM이 특정 작업을 수행하고, 특히 구조화된 데이터를 반환하도록 유도하는 효과적인 프롬프트 디자인 전략을 심층적으로 다룹니다. 웹페이지에서 필요한 링크를 추출하는 실제 예시를 통해 시스템 및 사용자 프롬프트 구성, JSON을 활용한 구조화, 그리고 OpenAI API의 `response_format` 기능을 활용하여 응답 형식을 강제하는 방법을 알아보겠습니다.

## 🛠️ 본문: LLM에게 명확한 길을 제시하는 방법

### 1. 효과적인 프롬프트 디자인의 시작: 시스템과 사용자 프롬프트

LLM과의 상호작용은 시스템 프롬프트와 사용자 프롬프트를 통해 시작됩니다. 이 둘은 LLM에게 그 역할과 수행할 작업을 명확히 지시하는 역할을 합니다.

*   **시스템 프롬프트 (System Prompt):** LLM의 전반적인 역할과 행동 방식을 정의합니다. 이는 LLM이 응답을 생성하는 데 있어 일관된 맥락을 제공합니다. 예를 들어, "당신은 웹페이지에서 발견된 링크 목록을 제공받았으며, 회사 브로슈어에 포함하기에 가장 적절한 링크(예: 회사 소개, 채용 정보 등)를 결정해야 합니다." 와 같이 LLM의 정체성과 목표를 설정할 수 있습니다.
*   **사용자 프롬프트 (User Prompt):** 특정 요청이나 입력 데이터를 포함합니다. 이 프롬프트는 LLM이 당면한 작업을 이해하고 처리하는 데 필요한 구체적인 정보를 제공합니다. 예를 들어, 특정 URL의 링크 목록을 전달하며 "이 웹사이트의 링크 목록입니다. 회사 브로슈어에 적합한 링크를 결정해주세요." 와 같이 구체적인 지시를 내립니다.

**예시: 시스템 프롬프트**

```
You are provided with a list of links found on a web page. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an about page or a company page, or a careers jobs page. You should respond in JSON as in this example:
```

이 시스템 프롬프트는 LLM의 역할을 정의하고, 응답 형식을 JSON으로 지정하며, 예시를 통해 원하는 출력 구조를 명확히 제시합니다.

### 2. LLM이 사랑하는 언어: JSON과 마크다운

LLM은 방대한 양의 데이터로 학습됩니다. 이 데이터는 크게 세 가지 범주로 나눌 수 있으며, 이 점을 이해하는 것이 효과적인 프롬프트 작성에 도움이 됩니다.

1.  **자연어 (Natural Language):** 수많은 영어 및 다양한 외국어 텍스트 데이터.
2.  **마크다운 (Markdown):** 웹사이트 콘텐츠 등이 변환된 형태. LLM은 마크다운 문법을 매우 잘 이해하고 생성합니다.
3.  **JSON (JavaScript Object Notation):** 구조화된 데이터 교환 형식. LLM은 JSON 데이터를 많이 접했기 때문에 JSON 구조에 매우 익숙합니다.

이러한 학습 배경 덕분에 LLM은 JSON 형식의 입력을 잘 이해하며, JSON 형식으로 응답을 생성하는 데 탁월한 능력을 보입니다. 데이터를 체계적으로 표현하고 싶을 때, 과거에 사람들이 사용했던 "첫 번째 항목은 ... 두 번째 항목은 ..."과 같은 서술적인 방식보다 JSON을 사용하는 것이 훨씬 안정적이고 효율적입니다.

**예시: LLM에 제시하는 JSON 구조**

```json
{
  "links": [
    {
      "type": "About Page",
      "url": "https://example.com/about"
    },
    {
      "type": "Careers Page",
      "url": "https://example.com/careers"
    }
  ]
}
```

위와 같이 `links`라는 키 아래에 `type`과 `url`을 가진 객체 목록을 포함하는 JSON 구조를 제시하면, LLM은 이 패턴을 학습하여 동일한 형식의 데이터를 생성할 가능성이 높아집니다.

### 3. LLM에게 길을 알려주는 방법: One-Shot 프롬프팅

LLM에게 원하는 응답을 얻는 가장 좋은 방법 중 하나는 **예시(Example)**를 제공하는 것입니다. 이를 **프롬프팅 기법**이라고 합니다.

*   **One-Shot 프롬프팅:** 하나의 질문-응답 예시를 제공하여 LLM이 원하는 형식을 학습하도록 유도합니다.
*   **Multi-Shot 프롬프팅:** 여러 개의 질문-응답 예시를 제공하여 더 복잡하거나 다양한 패턴을 학습시킵니다.

단순히 원하는 응답의 예시를 주는 것을 넘어, **원하지 않는 응답에 대한 지침**을 추가하는 것도 중요합니다. 예를 들어, "서비스 약관, 개인정보처리방침, 이메일 링크는 포함하지 마세요." 와 같은 명확한 금지 규칙을 제시할 수 있습니다. 이는 LLM이 예상치 못한 부적절한 내용을 포함하는 것을 방지하는 데 효과적입니다.

**예시: 사용자 프롬프트 (링크 추출)**

```python
def get_links_user_prompt(url: str, links: list) -> str:
    """
    주어진 URL과 링크 목록을 바탕으로 사용자 프롬프트를 생성합니다.
    """
    prompt = f"Here is a list of links on the website {url}:\n"
    for link in links:
        prompt += f"- {link}\n"
    prompt += "Please decide which of these are relevant web links for a brochure about the company. "
    prompt += "Respond with a full HTTPS URL in JSON format. "
    prompt += "Do not include terms of service, privacy, and email links."
    return prompt

# 사용 예시:
# user_prompt_content = get_links_user_prompt("https://www.example.com", ["/about", "/contact", "/privacy", "/careers"])
```

### 4. 반복과 실험의 중요성: LLM 엔지니어링의 핵심

LLM으로부터 최상의 결과를 얻기 위한 가장 중요한 원칙은 **실험과 반복(Experimentation and Iteration)**입니다. 처음부터 완벽한 프롬프트를 작성하기는 어렵습니다. 프롬프트는 지속적인 개선의 대상입니다.

만약 LLM이 관련 없는 개인정보처리방침 링크를 계속 포함한다면, 주저하지 말고 프롬프트에 "개인정보처리방침 링크는 포함하지 마세요."와 같은 명확한 지시를 추가해야 합니다. 이 과정은 데이터 과학자가 모델을 훈련하고 개선하는 방식과 유사하며, LLM 엔지니어링의 핵심 역량입니다. 프롬프트를 계속해서 다듬고, 예시를 추가하며, 개선하는 과정을 통해 원하는 결과를 얻을 수 있습니다.

### 5. OpenAI API를 활용한 구조화된 JSON 출력 제어

OpenAI의 `chat.completions.create` API 호출을 사용하여 LLM과 상호작용할 때, `response_format` 파라미터를 활용하면 응답 형식을 강제할 수 있습니다.

```python
import openai
import os
import json

# OpenAI 클라이언트 초기화 (API 키는 환경 변수 또는 설정 파일에서 로드)
# client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
# model = "gpt-4-turbo" # 사용할 LLM 모델 지정 (예: gpt-3.5-turbo, gpt-4)

def select_relevant_links(
    client: openai.OpenAI,
    model: str,
    system_prompt_content: str,
    user_prompt_content: str
) -> dict:
    """
    OpenAI API를 호출하여 웹페이지 링크 중 관련성 높은 링크를 JSON 형식으로 추출합니다.
    """
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt_content},
            {"role": "user", "content": user_prompt_content}
        ],
        response_format={"type": "json_object"} # JSON 응답 강제
    )
    
    # 응답 메시지 내용을 JSON으로 파싱
    try:
        return json.loads(response.choices[0].message.content)
    except json.JSONDecodeError:
        print("Received non-JSON response from LLM, attempting to re-parse or handle.")
        return {} # 에러 처리

# 예시 사용법 (실제 실행을 위해서는 client 및 model 정의 필요)
# system_prompt = "..." # 위에서 정의한 시스템 프롬프트 내용
# user_prompt = get_links_user_prompt("https://www.example.com", ["...", "..."]) # 위에서 정의한 사용자 프롬프트 내용
# relevant_links = select_relevant_links(client, model, system_prompt, user_prompt)
# print(relevant_links)
```

여기서 가장 주목할 부분은 `response_format={"type": "json_object"}` 파라미터입니다. 이 파라미터는 단순한 지시가 아니라, LLM의 추론 과정에서 **유효한 JSON만 생성되도록 강제**하는 강력한 기능입니다. LLM이 다음 토큰을 예측할 때, 이 기능은 유효하지 않은 JSON 구조를 만들 수 있는 토큰들을 후보에서 제외시켜 항상 올바른 JSON 형식을 유지하도록 합니다. 이는 LLM이 "JSON으로 응답하라"는 자연어 지시를 이해하는 것을 넘어, 기술적인 수준에서 형식적 제약을 가하는 것으로, LLM 애플리케이션의 견고성을 크게 향상시킵니다.

## 🏁 결론: 강력한 LLM 애플리케이션을 위한 핵심 전략

이 글에서는 LLM으로부터 정확하고 구조화된 응답을 얻기 위한 프롬프트 엔지니어링의 핵심 원칙들을 살펴보았습니다. 시스템 및 사용자 프롬프트를 명확히 분리하여 LLM의 역할과 작업을 정의하고, JSON을 활용하여 구조화된 데이터를 효율적으로 교환하며, One-Shot 프롬프팅을 통해 LLM에게 원하는 응답 패턴을 학습시키는 방법은 LLM 애플리케이션 개발의 필수적인 부분입니다.

특히 `response_format={"type": "json_object"}`와 같은 API의 강력한 기능을 활용하면, LLM이 항상 유효한 JSON 형식으로 응답하도록 강제할 수 있어 파싱 오류를 줄이고 개발 워크플로우를 단순화할 수 있습니다. 마지막으로, LLM 엔지니어링은 끊임없는 실험과 반복을 통해 최적의 프롬프트를 찾아가는 과정임을 기억해야 합니다. 이러한 전략들을 숙달함으로써, 여러분은 더욱 강력하고 안정적인 LLM 기반 애플리케이션을 구축할 수 있을 것입니다. 다음 단계로는 더 복잡한 스키마 기반의 구조화된 출력을 강제하는 "Structured Outputs"와 같은 고급 기법들을 탐구해볼 수 있습니다.