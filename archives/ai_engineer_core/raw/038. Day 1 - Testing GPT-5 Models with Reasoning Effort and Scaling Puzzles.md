# 038. 🧠 LLM 지능의 비밀- 모델 크기 vs 추론 노력

최근 대규모 언어 모델(LLM)의 발전은 개발자들에게 무궁무진한 가능성을 열어주었습니다. 하지만 이 강력한 도구를 효과적으로 활용하려면, LLM이 어떻게 '생각'하고 문제를 해결하는지 이해하는 것이 중요합니다. 이 글에서는 LLM의 추론 능력이 모델의 크기와 추론 노력(Reasoning Effort)이라는 두 가지 주요 요소에 의해 어떻게 달라지는지 탐구합니다. 흥미로운 퍼즐을 통해 LLM의 성능을 극대화하는 전략을 알아보세요.

## 💡 3줄 요약

*   LLM의 추론 능력은 모델 크기와 추론 노력 파라미터에 따라 크게 달라집니다.
*   `reasoning_effort`를 높이면 동일 모델에서도 복잡한 문제 해결 정확도가 향상됩니다.
*   '추론 시간' 스케일링은 '훈련 시간' 스케일링과 함께 LLM 성능 최적화를 위한 핵심 전략입니다.

---

## 🚀 서론: LLM, 똑똑한가? 얼마나 똑똑한가?

생성형 AI의 시대가 도래하며 LLM은 이제 우리 일상과 개발 워크플로우에 깊숙이 자리 잡았습니다. 이 똑똑해 보이는 AI 모델들이 과연 모든 질문에 완벽하게 답할 수 있을까요? 특히 인간에게도 헷갈릴 수 있는 '트릭 질문'이나 복잡한 논리 퍼즐에 대해서는 어떨까요?

이 아티클에서는 OpenAI의 최신 GPT-5 모델을 포함한 다양한 LLM들을 활용하여, 모델의 '지능'이 어떻게 발현되고 또 어떻게 조절될 수 있는지 실험 결과를 바탕으로 분석합니다. 우리는 특히 두 가지 중요한 스케일링 전략에 초점을 맞출 것입니다: 더 큰 모델을 사용하는 **훈련 시간 스케일링(Training-time Scaling)**과, 추론 과정에 더 많은 '생각' 시간을 할애하는 **추론 시간 스케일링(Inference-time Scaling)**입니다. 이 두 가지 접근 방식이 LLM의 문제 해결 능력에 미치는 영향을 퍼즐을 통해 알아보며, 개발자들이 LLM을 보다 전략적으로 활용할 수 있는 통찰을 제공하고자 합니다.

---

## 🧩 본론 1: LLM의 추론 능력 탐색 - 쉬운 퍼즐로 워밍업

첫 번째 실험에서는 비교적 간단하지만 함정이 숨어있는 확률 퍼즐을 통해 LLM의 기본적인 추론 능력을 테스트하고 `reasoning_effort` 파라미터를 소개합니다.

### `reasoning_effort` 파라미터 소개

최신 GPT-5 모델에서는 `reasoning_effort`라는 새로운 파라미터를 사용할 수 있습니다. 이 파라미터는 모델이 답변을 생성하기 위해 얼마나 많은 추론 노력을 기울일 것인지를 설정합니다. 설정 가능한 값은 다음과 같습니다:

*   **minimal:** 가장 빠른 응답을 목표로 하지만, 정확도가 낮을 수 있습니다. (챗봇 모델과 유사한 속도)
*   **low:** 최소한의 노력보다는 조금 더 추론합니다.
*   **medium:** 적당한 추론 노력을 기울입니다.
*   **high:** 가장 높은 추론 노력을 기울여 정확도를 극대화하지만, 응답 시간이 길어질 수 있습니다.

이 파라미터는 모델의 속도와 정확도 사이의 균형을 조절할 수 있게 해, 특정 유스케이스에 맞춰 LLM의 동작을 최적화할 수 있도록 돕습니다.

### "두 개의 동전" 퍼즐

다음은 첫 번째 퍼즐입니다.

> **퍼즐 1:** 두 개의 동전을 던졌는데, 그중 하나가 앞면입니다. 다른 하나가 뒷면일 확률은 얼마일까요? (확률만 숫자로 답변하세요.)

직관적으로 1/2이라고 생각하기 쉽지만, 이 문제는 조건부 확률이 적용되는 함정 문제이며 정답은 2/3입니다. 가능한 모든 경우의 수는 (앞면, 앞면), (앞면, 뒷면), (뒷면, 앞면), (뒷면, 뒷면) 네 가지입니다. "하나가 앞면"이라는 조건이 주어졌으므로, (뒷면, 뒷면)을 제외한 (앞면, 앞면), (앞면, 뒷면), (뒷면, 앞면) 세 가지 경우가 남습니다. 이 세 가지 경우 중 다른 하나가 뒷면인 경우는 (앞면, 뒷면)과 (뒷면, 앞면) 두 가지이므로, 확률은 2/3이 됩니다.

이제 이 퍼즐에 대한 GPT-5 모델들의 답변을 살펴보겠습니다.

#### GPT-5 nano (가장 작은 모델) 실험 결과

1.  **GPT-5 nano, `reasoning_effort="minimal"`:**
    *   답변: `1/3` (오답)
    *   가장 작은 모델에 최소한의 추론 노력을 주었을 때, 올바른 답변을 찾지 못했습니다.

2.  **GPT-5 nano, `reasoning_effort="low"`:**
    *   답변: `2/3` (정답)
    *   동일한 GPT-5 nano 모델이지만, 추론 노력을 'minimal'에서 'low'로 약간만 높였을 때 정답을 맞혔습니다.

#### GPT-5 mini (조금 더 큰 모델) 실험 결과

1.  **GPT-5 mini, `reasoning_effort="minimal"`:**
    *   답변: `2/3` (정답)
    *   `reasoning_effort`는 'minimal'로 유지했지만, 모델 크기를 GPT-5 nano보다 큰 GPT-5 mini로 변경했을 때도 정답을 맞혔습니다.

#### 실험 결과 요약 및 코드 예시

| 모델            | `reasoning_effort` | 답변 | 정확성 |
| :-------------- | :----------------- | :--- | :----- |
| GPT-5 nano      | `minimal`          | 1/3  | ❌     |
| GPT-5 nano      | `low`              | 2/3  | ✅     |
| GPT-5 mini      | `minimal`          | 2/3  | ✅     |

```python
import openai

client = openai.OpenAI(api_key="YOUR_API_KEY")

puzzle_prompt = "두 개의 동전을 던졌는데, 그중 하나가 앞면입니다. 다른 하나가 뒷면일 확률은 얼마일까요? 확률만 숫자로 답변하세요."

# 1. GPT-5 nano, minimal reasoning
response_nano_minimal = client.chat.completions.create(
    model="gpt-5-nano",
    messages=[{"role": "user", "content": puzzle_prompt}],
    reasoning_effort="minimal"
)
print(f"GPT-5 nano (minimal): {response_nano_minimal.choices[0].message.content}")

# 2. GPT-5 nano, low reasoning
response_nano_low = client.chat.completions.create(
    model="gpt-5-nano",
    messages=[{"role": "user", "content": puzzle_prompt}],
    reasoning_effort="low"
)
print(f"GPT-5 nano (low): {response_nano_low.choices[0].message.content}")

# 3. GPT-5 mini, minimal reasoning
response_mini_minimal = client.chat.completions.create(
    model="gpt-5-mini", # 더 큰 모델
    messages=[{"role": "user", "content": puzzle_prompt}],
    reasoning_effort="minimal"
)
print(f"GPT-5 mini (minimal): {response_mini_minimal.choices[0].message.content}")
```

이 간단한 퍼즐은 LLM의 정확도를 높이는 두 가지 주요 경로를 명확하게 보여줍니다:
1.  **추론 노력을 증가시키는 것 (Inference-time Scaling):** 동일한 모델 내에서 더 많은 계산 자원을 할애하여 추론 과정을 심화합니다.
2.  **더 큰 모델을 사용하는 것 (Training-time Scaling):** 더 많은 파라미터와 학습 데이터를 가진 모델을 사용하여, 기본적인 지능과 문제 해결 능력을 향상시킵니다.

---

## 📚 본론 2: 고난도 퍼즐 도전 - LLM의 한계와 가능성

이제 조금 더 복잡한, 고전적인 '트릭 퍼즐'을 통해 최신 LLM들이 얼마나 깊이 있는 추론을 할 수 있는지 테스트해봅니다.

### "책벌레" 퍼즐 소개

이 퍼즐은 과거 한 학생이 제시한 것으로, 많은 사람이 틀리곤 하지만 어린아이들은 종종 정답을 맞히는 흥미로운 문제입니다.

> **퍼즐 2:** 책꽂이에 러시아 시인 푸쉬킨의 두 권의 책, 1권과 2권이 나란히 꽂혀 있습니다. 각 권의 페이지 두께는 2cm이고, 각 표지 두께는 2mm입니다. 한 책벌레가 1권의 첫 페이지부터 2권의 마지막 페이지까지 책들을 관통하여 갉아먹었습니다. 책벌레가 이동한 거리는 얼마일까요?

이 문제는 단순히 숫자를 더하는 것이 아니라, 책이 책꽂이에 꽂혀 있는 방식을 시각화해야 하는 문제입니다.

*   책꽂이에 책이 꽂혀 있을 때, 1권은 2권의 왼쪽에 있습니다.
*   책의 '첫 페이지'는 책을 펼쳤을 때 가장 오른쪽에 있는 페이지이며, '마지막 페이지'는 가장 왼쪽에 있는 페이지입니다.
*   즉, 1권의 '첫 페이지'는 1권의 맨 앞장(표지 바로 다음)에 해당하고, 2권의 '마지막 페이지'는 2권의 맨 뒷장(표지 바로 앞)에 해당합니다.
*   책벌레는 1권의 첫 페이지(1권의 내부)에서 시작하여, 1권의 뒷표지를 뚫고, 2권의 앞표지를 뚫은 다음, 2권의 마지막 페이지(2권의 내부)에서 멈춥니다.
*   따라서 책벌레가 실제로 갉아먹은 거리는 **1권의 뒷표지 두께 + 2권의 앞표지 두께**가 됩니다.
*   각 표지 두께는 2mm이므로, 총 이동 거리는 2mm + 2mm = **4mm**입니다.

### 다양한 모델들의 도전 결과

이 까다로운 퍼즐에 대해 GPT-5 nano는 어떻게 반응했을까요?

1.  **GPT-5 nano, `reasoning_effort="low"`:**
    *   답변: `4.3cm` (오답)
    *   가장 작은 모델은 'low' 추론 노력으로도 정답을 찾지 못했습니다. 이는 직관적인 계산 오류를 포함한 답변으로 보입니다.

강사는 이어서 Claude Sonnet 4.5, GPT-5, Gemini 2.5 Pro와 같은 가장 강력한 모델들에게 이 질문을 던졌습니다. Grok 4는 테스트 당시 몇 분 안에 답변을 내놓지 못할 정도로 어려워했습니다. 이 결과는 아무리 강력한 LLM이라도, 인간적인 관점의 '트릭'이나 복잡한 공간 추론이 필요한 문제에서는 어려움을 겪을 수 있음을 시사합니다.

강력한 모델들이 이 문제에 대해 어떤 답변을 내놓았을지는 다음 단계의 과제로 남겨두었지만, 이러한 퍼즐은 LLM의 한계를 이해하고, 그들이 특정 유형의 문제에 어떻게 접근하는지 학습하는 데 중요한 지표가 됩니다.

---

## 📈 본론 3: LLM 스케일링 전략 - 훈련 시간 vs 추론 시간

두 퍼즐을 통해 우리는 LLM의 성능을 높이는 두 가지 주요 스케일링 전략의 중요성을 확인했습니다.

### 훈련 시간 스케일링 (Training-time Scaling)

더 많은 파라미터와 더 방대한 데이터셋으로 훈련된 **더 큰 모델을 사용하는 것**을 의미합니다.

*   **예시:** GPT-5 nano에서 GPT-5 mini로 전환
*   **장점:** 모델의 기본적인 지능, 일반화 능력, 그리고 복잡한 패턴을 인식하는 능력이 향상됩니다.
*   **단점:** 더 큰 모델은 추론 비용이 더 많이 들고, 응답 시간이 길어질 수 있으며, 더 많은 컴퓨팅 자원을 요구합니다.

### 추론 시간 스케일링 (Inference-time Scaling)

**`reasoning_effort`와 같은 파라미터를 조절하여** 모델이 추론 단계에서 더 많은 '생각' 시간이나 자원을 할애하도록 하는 것을 의미합니다.

*   **예시:** GPT-5 nano의 `reasoning_effort`를 `minimal`에서 `low`로 변경
*   **장점:** 동일한 모델 내에서 비용 효율적으로 정확도를 향상시킬 수 있습니다. 특히 복잡하거나 함정이 있는 문제에서 유용합니다.
*   **단점:** 모델 자체의 근본적인 한계를 넘어서지는 못하며, `reasoning_effort`를 너무 높이면 응답 지연이 발생합니다.

#### 스케일링 전략 비교

| 스케일링 유형     | 방법                         | 장점                             | 단점                             |
| :---------------- | :--------------------------- | :------------------------------- | :------------------------------- |
| **훈련 시간**     | 더 큰 모델 (예: GPT-5 mini) | 기본 지능 및 성능 향상, 복잡성 처리 능력 증대 | 비용 증가, 추론 지연, 자원 소모 |
| **추론 시간**     | `reasoning_effort` 조절      | 비용 효율적으로 정확도 향상, 유연성 | 모델의 근본 한계 내, 응답 지연 가능 |

### 언제 어떤 전략을 사용할까?

*   **일반적인 작업, 비용/속도 민감도 높은 경우:** 작은 모델과 `minimal` 또는 `low` `reasoning_effort`로 시작합니다.
*   **복잡하거나 중요한 작업, 정확도 우선:** `reasoning_effort`를 `medium` 또는 `high`로 높여 모델의 추론을 심화시킵니다.
*   **추론 시간 스케일링으로도 부족할 때:** 더 큰 모델로 전환하는 것을 고려합니다.

이러한 전략적 접근은 비용을 효율적으로 관리하면서도, 필요한 상황에서 LLM의 최대 성능을 끌어낼 수 있게 합니다.

---

## 🎯 결론: LLM을 현명하게 활용하는 개발자를 위한 조언

이번 실험을 통해 우리는 LLM이 단순히 텍스트를 생성하는 도구를 넘어, 그들의 '사고 과정'을 이해하고 조절할 수 있는 정교한 시스템임을 확인했습니다. "두 개의 동전" 퍼즐은 `reasoning_effort` 파라미터와 모델 크기가 LLM의 문제 해결 정확도에 얼마나 큰 영향을 미치는지 보여주었으며, "책벌레" 퍼즐은 최신/최강의 모델들도 특정 유형의 추론 문제에서 여전히 어려움을 겪을 수 있음을 시사했습니다.

개발자 여러분은 LLM을 활용하여 애플리케이션을 구축할 때, 단순히 모델의 이름에만 의존하지 말고 다음 사항을 고려해야 합니다:

1.  **모델 선택의 전략화:** 해결하려는 문제의 복잡성과 중요도에 따라 적절한 크기의 모델을 선택합니다.
2.  **`reasoning_effort`의 활용:** 특히 논리적 추론이나 복잡한 분석이 필요한 작업에서는 `reasoning_effort` 파라미터를 조정하여 모델의 깊이 있는 사고를 유도합니다. 이는 때때로 더 큰 모델을 사용하는 것보다 비용 효율적인 해결책이 될 수 있습니다.
3.  **LLM의 한계 이해:** LLM은 강력하지만 만능이 아닙니다. 특히 인간적인 직관이나 특정 유형의 '트릭'에 대한 이해는 여전히 발전 중인 영역입니다. 중요한 결정에는 LLM의 답변을 맹신하기보다 검증 과정을 포함하는 것이 현명합니다.

LLM의 성능은 끊임없이 진화하고 있으며, `reasoning_effort`와 같은 파라미터들은 개발자들이 이 진화를 자신의 애플리케이션에 맞게 최적화할 수 있도록 돕는 중요한 도구입니다. 모델의 특성과 스케일링 전략을 깊이 이해하고 실험하며, 더욱 견고하고 지능적인 AI 솔루션을 구축해 나가시길 바랍니다.