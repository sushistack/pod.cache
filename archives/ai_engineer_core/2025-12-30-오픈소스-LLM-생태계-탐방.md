---
type: ai_engineer_core
number: 15
---

## 2025-12-30 오픈소스 LLM 생태계 탐방 - 주요 모델과 활용 전략

[📄 원본 파일 보기](raw/015.%20Day%202%20-%20Open-Source%20LLMs%20LLaMA%2C%20Mistral%2C%20DeepSeek%2C%20and%20Ollama.md)


<details>
<summary>오픈소스 LLM 모델과 활용 전략</summary>

### 급부상하는 오픈소스 LLM 리더들

- Meta의 Llama 시리즈: 오픈소스 AI의 선구자
- 혁신적인 아키텍처, Mistral
- 숨겨진 강자들: Qwen, Gemma, Phi
- 효율성 혁명, DeepSeek & OpenAI의 GPT-OS

### LLM 활용을 위한 세 가지 접근 방식 (추론 Inference)

1. 제품 형태의 서비스 이용
2. 클라우드 기반 API 호출
3. 오픈소스 모델 로컬 직접 실행


#### Hugging Face Transformers 라이브러리

- 설명: Hugging Face Transformers는 다양한 신경망 모델(LLM 포함)을 구현한 파이썬 및 C++ 코드와 미리 훈련된 가중치를 제공하는 라이브러리입니다. 개발자는 이 코드를 직접 다운로드하여 자신의 파이썬 환경에서 모델을 실행할 수 있습니다. 모델의 내부 동작을 가장 깊이 있게 이해하고 커스터마이징할 수 있는 방법입니다.
- 장점: 유연성이 매우 높고, 광범위한 모델 지원.
- 단점: 로컬 환경 설정 및 최적화에 대한 이해가 필요.


#### Ollama

- 설명: Ollama는 오픈소스 모델을 로컬에서 쉽고 효율적으로 실행할 수 있도록 패키징된 '제품'입니다. 특정 모델 버전을 C++로 최적화하고 가중치를 .gguf 파일과 같은 효율적인 형식으로 압축하여 제공합니다. 이를 통해 개발자는 몇 가지 간단한 명령만으로 로컬 컴퓨터에서 모델을 구동하고, 로컬 API를 통해 모델과 상호작용할 수 있습니다.
- 장점: 설치 및 사용이 매우 간편하며, 효율적인 로컬 추론 성능 제공.
- 단점: 지원하는 모델의 범위가 Hugging Face에 비해 제한적일 수 있습니다.


</details>
