---
type: ai_engineer_core
number: 30
---

## 2025-12-31 LLM의 기억: 환상과 현실

[📄 원본 파일 보기](raw/030.%20Day%204%20-%20Tokenizing%20with%20tiktoken%20and%20Understanding%20the%20Illusion%20of%20Memory.md)


<details>
<summary>LLM의 기억과 비용</summary>

### LLM은 기억하는 것 처럼 보일까?

그렇다면 ChatGPT와 같은 서비스는 어떻게 이전 대화를 기억하는 것처럼 보이는 걸까요? 그 비밀은 바로 **"대화 기록 전체를 매번 새로운 요청으로 전달"**하는 트릭에 있습니다.

- 개발자가 직접 모든 이전 메시지를 포함하여 현재까지의 전체 대화 기록을 messages 리스트에 담아 매번 API 호출에 전달해야 합니다.
- 이때, role 필드는 system, user 외에 assistant를 사용하여 모델의 이전 응답도 함께 포함

### 비용과 성능 트레이드오프

- 더 많은 입력 토큰: 대화가 길어질수록 messages 리스트에 포함되는 토큰의 수가 증가합니다.
- 더 많은 컴퓨팅 자원: LLM은 입력으로 들어온 전체 토큰 시퀀스를 기반으로 다음 토큰을 예측해야 하므로, 토큰 수가 많아질수록 더 많은 컴퓨팅 자원을 소모합니다. 이는 곧 응답 시간 증가와 API 사용 비용 증가로 이어집니다.
- 효율적인 LLM 애플리케이션 설계를 위해서는 대화 길이 관리, 요약 기법 도입, 캐싱 등 다양한 최적화 전략을 고려.

</details>
